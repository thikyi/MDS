{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd34dd26-04a3-442a-abc1-648d97bb66ae",
   "metadata": {},
   "source": [
    "# Assignment 28: Combining Pandas DataFrames #\n",
    "\n",
    "### Goals for this Assignment ###\n",
    "\n",
    "By the time you have completed this assignment, you should be able to:\n",
    "\n",
    "- Use Pandas' `concat` function to combine two Pandas `DataFrame` objects\n",
    "- Use the `merge` method on Pandas `DataFrame` objects to perform an _inner join_ with another `DataFrame`\n",
    "- Use the `merge` method on Pandas `DataFrame` objects to perform an _outer join_ with another `DataFrame`\n",
    "\n",
    "## Step 1: Use `concat` To Combine two Pandas `DataFrame` Objects ##\n",
    "\n",
    "### Background: Combining Multiple `DataFrame`s ###\n",
    "\n",
    "Sometimes we want to combine multiple `DataFrame` objects together into a single `DataFrame`.\n",
    "For example, say a doctor's office tracks the last blood pressure reading from its patients.\n",
    "Because of the sheer volume of patients, readings are divided into separate files, based on the first character of the patient's name.\n",
    "For example, we might have one file associated with patients whose names start with \"a\":\n",
    "\n",
    "| Patient Name | Age | Blood Pressure |\n",
    "| ------------ | --- | -------------- |\n",
    "| Abigail      | 45  | 135            |\n",
    "| Adam         | 57  | 122            |\n",
    "| Alice        | 25  | 118            |\n",
    "| Andrew       | 62  | 121            |\n",
    "\n",
    "\n",
    "...and another file associated with patients whose names start with \"b\":\n",
    "\n",
    "| Patient Name | Age | Blood Pressure |\n",
    "| ------------ | --- | -------------- |\n",
    "| Barbara      | 30  | 132            |\n",
    "| Bob          | 22  | 135            |\n",
    "| Bill         | 43  | 126            |\n",
    "\n",
    "While this split might make sense from a data storage perspective (e.g., reducing the size of any individual file), this probably does not make much sense from an analysis perspective.\n",
    "That is, you're more likely to want to analyze all patients, not just the ones whose name starts with a given letter.\n",
    "The bad news here is that you're forced into reading all these files separately, leading to a separate `DataFrame` object for each file.\n",
    "This is not conducive to doing analyses over all patients.\n",
    "\n",
    "The good news is that Pandas offers a number of ways to combine multiple `DataFrame` objects together.\n",
    "One way to do this is via `concat`, which takes a list of `DataFrame` objects to concatenate together.\n",
    "This is shown in the next cell, using the data from the above two tables as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf6935c-f100-45ba-bf7c-a2728c85577c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name  age  blood_pressure\n",
      "0  abigail   45             135\n",
      "1     adam   57             122\n",
      "2    alice   25             118\n",
      "3   andrew   62             121\n",
      "0  barbara   30             132\n",
      "1      bob   22             135\n",
      "2     bill   43             126\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "patients_a = pd.DataFrame({\"name\": [\"abigail\", \"adam\", \"alice\", \"andrew\"],\n",
    "                           \"age\": [45, 57, 25, 62],\n",
    "                           \"blood_pressure\": [135, 122, 118, 121]})\n",
    "patients_b = pd.DataFrame({\"name\": [\"barbara\", \"bob\", \"bill\"],\n",
    "                           \"age\": [30, 22, 43],\n",
    "                           \"blood_pressure\": [132, 135, 126]})\n",
    "patients_combined = pd.concat([patients_a, patients_b])\n",
    "print(patients_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c227231b-b1d8-4c14-a66c-e02bd9ef3511",
   "metadata": {},
   "source": [
    "If you run the above cell, you'll see all the data from both `DataFrame` objects put into the same output `DataFrame` object.\n",
    "However, if you look closely, there is something strange: **multiple** rows have the same index!\n",
    "This is not just some weird artifact of `print`ing this out, as shown in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f2f94a0-0e9b-419b-9dbf-43c109d728ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    abigail\n",
      "0    barbara\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(patients_combined[\"name\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b2f0db-2465-49ee-91fc-63fde0a85b57",
   "metadata": {},
   "source": [
    "If you run the above cell, you'll see that this gives you back a Pandas `Series` object, containing both `\"abigail\"` and `\"barbara\"`.\n",
    "That is, _both_ are at row index `0`.\n",
    "This is because `concat`, by default, maintains the original row indices from all of its input `DataFrame` objects.\n",
    "This behavior makes sense given the knowledge that row indices can be user-controlled (and therefore given meaningful names), but in this case, we only are using numeric identifiers which are intended to be sequential.\n",
    "\n",
    "We can address this situation by telling `concat` to ignore the original row indices, as shown in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b7bffc6-f2ba-4ae7-838e-60fbe1579d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name  age  blood_pressure\n",
      "0  abigail   45             135\n",
      "1     adam   57             122\n",
      "2    alice   25             118\n",
      "3   andrew   62             121\n",
      "4  barbara   30             132\n",
      "5      bob   22             135\n",
      "6     bill   43             126\n"
     ]
    }
   ],
   "source": [
    "patients_combined = pd.concat([patients_a, patients_b], ignore_index=True)\n",
    "print(patients_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c860e1e-b3b7-4cad-afe7-cac0054f0f91",
   "metadata": {},
   "source": [
    "If the above cell is run, you'll see that now each row has its own unique index.\n",
    "This is further demonstrated in the next cell where we access the same row index again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e682fce-6bfd-4ee7-ae8e-c16b3901a47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abigail\n"
     ]
    }
   ],
   "source": [
    "print(patients_combined[\"name\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b58a91-c659-4256-988a-b22dab4fd05e",
   "metadata": {},
   "source": [
    "If run, you'll see that this now gives us the name `\"abigail\"`, as opposed to a Pandas `Series` object containing names.\n",
    "\n",
    "### Try this Yourself ###\n",
    "\n",
    "In the next cell, there are two `DataFrame` objects `furniture_first` and `furniture_second` with the same columns representing an inventory of furniture.\n",
    "Combine these two into a single `DataFrame` object `furniture_combined`, using `concat`.\n",
    "Each row should have a unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d547eed-dd51-4772-9061-5cc4f8c48fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name  price\n",
      "0    table    150\n",
      "1    chair     80\n",
      "2    couch    500\n",
      "3      bed    600\n",
      "4  dresser    200\n"
     ]
    }
   ],
   "source": [
    "furniture_first = pd.DataFrame({\"name\": [\"table\", \"chair\", \"couch\"],\n",
    "                                \"price\": [150, 80, 500]})\n",
    "furniture_second = pd.DataFrame({\"name\": [\"bed\", \"dresser\"],\n",
    "                                 \"price\": [600, 200]})\n",
    "\n",
    "# write your code here which will create furniture_combined with the help\n",
    "# of Pandas' concat\n",
    "furniture_combined = pd.concat([furniture_first, furniture_second], ignore_index=True)\n",
    "\n",
    "print(furniture_combined)\n",
    "# above statement should print:\n",
    "#       name  price\n",
    "# 0    table    150\n",
    "# 1    chair     80\n",
    "# 2    couch    500\n",
    "# 3      bed    600\n",
    "# 4  dresser    200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280de8d9-d484-45c8-b779-3cc6fc7efc09",
   "metadata": {},
   "source": [
    "## Step 2: Use `merge` To Combine two Pandas `DataFrame` Objects via an Inner Join ##\n",
    "\n",
    "### Background: Inner Joins ###\n",
    "\n",
    "Sometimes we have two closely-related `DataFrame` objects which share some, but not all columns.\n",
    "For example, say we are representing the following information with two files at a hardware store:\n",
    "\n",
    "1. A file containing inventory information.  This includes which items are available, their prices, their availabile quantities, and what locations the items are in.  Each individual item in inventory could be represented as a separate row.\n",
    "2. A file containing customer purchase information.  This includes columns for who purchased what, and when.  Each individual item purchased could be represented as a separate row.\n",
    "\n",
    "It would arguably not make sense to track all this information in the same file (or at least within the same table), given that there are columns which are not shared by both tables.\n",
    "Nonetheless, there is _some_ overlap between columns, namely, specific items.\n",
    "Moreover, there are situations in which an analysis might need information from both files.\n",
    "For example, if we want to determine how much a given customer should have paid on a given day, we would need to cross-reference purchase information from the second file against price information in the first file.\n",
    "For ease of analysis, it would make the most sense to somehow put this cross-referenced information into a single `DataFrame`.\n",
    "This means that ultimately, we need a way to combine the `DataFrame` objects corresponding to the two files above into a single `DataFrame` object holding cross-referenced information.\n",
    "\n",
    "While we saw that `concat` can be used to combine `DataFrame` objects, it is not well-suited to this sort of cross-referencing.\n",
    "This is shown in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c82ef23b-e1b9-46a7-a5b2-e4c8255ee1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product  price  quantity  location customer_name      when\n",
      "0       hammer   20.0      19.0     tools           NaN       NaN\n",
      "1       wrench   30.0      15.0     tools           NaN       NaN\n",
      "2  screws (20)    2.5     150.0  hardware           NaN       NaN\n",
      "3       hammer    NaN       NaN       NaN         alice  1/2/2025\n",
      "4       wrench    NaN       NaN       NaN         alice  1/2/2025\n",
      "5  screws (20)    NaN       NaN       NaN           bob  3/4/2025\n",
      "6       hammer    NaN       NaN       NaN           joe  5/6/2025\n"
     ]
    }
   ],
   "source": [
    "hardware_inventory = pd.DataFrame({\"product\": [\"hammer\", \"wrench\", \"screws (20)\"],\n",
    "                                   \"price\": [20, 30, 2.5],\n",
    "                                   \"quantity\": [19, 15, 150],\n",
    "                                   \"location\": [\"tools\", \"tools\", \"hardware\"]})\n",
    "\n",
    "# alice bought a hammer and a wrench on 1/2/2025,\n",
    "# bob bought screws on 3/4/2025, and joe bought a hammer on 5/6/2025.\n",
    "# Note that Pandas has much better representations for dates/times, but they\n",
    "# are beyond our scope and have been simplified to strings\n",
    "hardware_purchases = pd.DataFrame({\"customer_name\": [\"alice\", \"alice\", \"bob\", \"joe\"],\n",
    "                                   \"product\": [\"hammer\", \"wrench\", \"screws (20)\", \"hammer\"],\n",
    "                                   \"when\": [\"1/2/2025\", \"1/2/2025\", \"3/4/2025\", \"5/6/2025\"]})\n",
    "\n",
    "print(pd.concat([hardware_inventory, hardware_purchases], ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed34b04-d2f1-453c-b103-4ba23a888726",
   "metadata": {},
   "source": [
    "If you run the cell above, you'll see a whole lot of `NaN`s appearing in the data.\n",
    "The columns of the concatenated table are based on the set union of the columns from the original data, meaning every row now contains columns from both data sets.\n",
    "However, depending on which data set the row came from, there will always be some columns that don't have values for that row, and `NaN` gets used in these places.\n",
    "While the `DataFrame` objects have technically been combined, they have not been meaningfully cross-referenced.\n",
    "\n",
    "This sort of cross-referencing is best done instead by the `merge` method on `DataFrame` objects.\n",
    "The `merge` method takes another `DataFrame` object.\n",
    "By default, merge will perform this cross-referencing with any overlapping columns, though it's usually a good idea to manually specify which column to perform the cross-referencing with by passing the optional `on` keyword parameter.\n",
    "This is shown in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a46c23d0-94d9-4408-bfdc-a828d8f7a284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product  price  quantity  location customer_name      when\n",
      "0       hammer   20.0        19     tools         alice  1/2/2025\n",
      "1       hammer   20.0        19     tools           joe  5/6/2025\n",
      "2       wrench   30.0        15     tools         alice  1/2/2025\n",
      "3  screws (20)    2.5       150  hardware           bob  3/4/2025\n"
     ]
    }
   ],
   "source": [
    "cross_referenced = hardware_inventory.merge(hardware_purchases, on=\"product\")\n",
    "print(cross_referenced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476261e4-b683-4b31-8bb6-d5644da4762e",
   "metadata": {},
   "source": [
    "If you run the cell above, you'll see that you have all the same columns as from the call to `concat`.\n",
    "However, the number of rows now corresponds to the number of rows now corresponds to the number of rows in `hardware_purchases`.\n",
    "There is no information about price, quantity, and location in the `hardware_purchases` `DataFrame`.\n",
    "For those missing values, `merge` consulted the `hardware_inventory` table, specifically looking for the row information corresponding to a value with the same column value as `\"product\"`.\n",
    "For example, the `\"price\"` column for row `0` was determined by taking the `\"price\"` information for `\"hammer\"` in `hardware_inventory`.\n",
    "Importantly, both `hardware_inventory` and `hardware_purchases` have a `\"product\"` column containing the same sorts of values, allowing for this cross-referencing to even be possible.\n",
    "\n",
    "Now that we have this cross-referenced `DataFrame`, we can much more easily perform analyses that require information from both tables.\n",
    "For example, to determine the total value of all of Alice's purchases, we can now do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4177495c-383a-4042-867f-d5a68858c214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n"
     ]
    }
   ],
   "source": [
    "print(cross_referenced[cross_referenced[\"customer_name\"] == \"alice\"][\"price\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66eab5a-dd4c-400e-b8f1-8367c028da3b",
   "metadata": {},
   "source": [
    "This would not have been possible to do so concisely if we had to work with multiple `DataFrame` tables, and likely would have necessitated a loop (with all the extra code and performance drawbacks).\n",
    "\n",
    "The sort of cross-referencing shown is known as a _join_, borrowing terminology from [joins in Structured Query Language (SQL)](https://en.wikipedia.org/wiki/Join_(SQL)#Inner_join_and_NULL_values).\n",
    "To explain this terminology, the idea is that we can view the values within whatever column we are joining on as a set.\n",
    "Because we have two columns in play with the same sorts of values (one `\"product\"` column from `hardware_inventory`, and another `\"product\"` column from `hardware_purchases`), we have two sets in play.\n",
    "We can visually represent this as a Venn diagram, shown below:\n",
    "\n",
    "![venn1](venn1.png)\n",
    "\n",
    "There are a number of different kinds of joins, which all refer to a two-set Venn diagram, same as the above.\n",
    "The distinction between these joins is based on what parts of the diagram we are attempting to show in the result.\n",
    "For example, we specifically performed an _inner join_ when we created `cross_referenced` above, which is the default of the `merge` method.\n",
    "An inner join requests the intersection between the two parts of the Venn diagram, that is, the inner overlapping part of the diagram.\n",
    "Relevant to Pandas, the `merge` method also supports (among others):\n",
    "\n",
    "- Left joins, which only use the values from the leftmost `DataFrame`.  In the Venn diagram, this is everything in the left circle.\n",
    "- Right joins, which only use the values from the rightmost `DataFrame`.  In the Venn diagram, this is everything in the right circle.\n",
    "- Outer joins, which use all the values from both `DataFrame`s.  In the Venn diagram, this is everything.\n",
    "\n",
    "In this specific example, since all keys involved are in the intersection, all these different kinds of joins will result in the same row data, though the ordering of the rows will differ based on the join type.\n",
    "In the next step we will look at some of these other joins, but for now we will only consider inner joins.\n",
    "\n",
    "### Try this Yourself ###\n",
    "\n",
    "In the next cell, `DataFrame` objects for `patients` and `blood_pressures` have been defined.\n",
    "Unlike the prior data, this format separates the age of patients into the `patients` `DataFrame`.\n",
    "Individual blood pressure readings are in the `blood_pressures` table, which now has multiple readings for different patients over time.\n",
    "\n",
    "You need to do two things in this cell:\n",
    "\n",
    "1. Using `merge` with an inner join, cross-reference these two `DataFrame`s into a single `DataFrame`, based on the patient name.\n",
    "2. On this joined `DataFrame`, compute the average blood pressure reading across all readings for patients under 50 years old.  Print out the result of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef3dbe22-d2d3-4351-a3af-4e6bcfd20161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name  age  blood_pressure      when\n",
      "0     alex   45             135  1/2/2025\n",
      "1      bob   57             122  1/3/2020\n",
      "2      bob   57             118  1/7/2023\n",
      "3    megan   42             121  2/4/2020\n",
      "4    megan   42             132  5/6/2023\n",
      "5    megan   42             135  8/2/2024\n",
      "6     john   62             126  1/2/2024\n",
      "7     john   62             132  1/3/2025\n",
      "8     mary   48             124  1/4/2020\n",
      "9     mary   48             120  1/8/2023\n",
      "10    mary   48             119  6/2/2024\n",
      "11  maggie   27             136  1/3/2020\n",
      "12     sam   21             127  2/4/2020\n",
      "13     sam   21             139  5/6/2023\n",
      "\n",
      "128.8\n"
     ]
    }
   ],
   "source": [
    "patients = pd.DataFrame({\"name\": [\"alex\", \"bob\", \"megan\", \"john\", \"mary\", \"maggie\", \"sam\"],\n",
    "                         \"age\": [45, 57, 42, 62, 48, 27, 21]})\n",
    "blood_pressures = pd.DataFrame({\"name\": [\"alex\", \"bob\", \"bob\", \"megan\", \"megan\", \"megan\", \"john\",\n",
    "                                         \"john\", \"mary\", \"mary\", \"mary\", \"maggie\", \"sam\", \"sam\"],\n",
    "                                \"blood_pressure\": [135, 122, 118, 121, 132, 135, 126,\n",
    "                                                   132, 124, 120, 119, 136, 127, 139],\n",
    "                                \"when\": [\"1/2/2025\", \"1/3/2020\", \"1/7/2023\", \"2/4/2020\", \"5/6/2023\", \"8/2/2024\", \"1/2/2024\",\n",
    "                                         \"1/3/2025\", \"1/4/2020\", \"1/8/2023\", \"6/2/2024\", \"1/3/2020\", \"2/4/2020\", \"5/6/2023\"]})\n",
    "\n",
    "# Write your statement here which will do an inner join of patients and blood_pressures\n",
    "# You should then bind this to the variable combined_patients\n",
    "combined_patients = patients.merge(blood_pressures, on=\"name\")\n",
    "\n",
    "print(combined_patients)\n",
    "# above statement should print:\n",
    "#       name  age  blood_pressure      when\n",
    "# 0     alex   45             135  1/2/2025\n",
    "# 1      bob   57             122  1/3/2020\n",
    "# 2      bob   57             118  1/7/2023\n",
    "# 3    megan   42             121  2/4/2020\n",
    "# 4    megan   42             132  5/6/2023\n",
    "# 5    megan   42             135  8/2/2024\n",
    "# 6     john   62             126  1/2/2024\n",
    "# 7     john   62             132  1/3/2025\n",
    "# 8     mary   48             124  1/4/2020\n",
    "# 9     mary   48             120  1/8/2023\n",
    "# 10    mary   48             119  6/2/2024\n",
    "# 11  maggie   27             136  1/3/2020\n",
    "# 12     sam   21             127  2/4/2020\n",
    "# 13     sam   21             139  5/6/2023\n",
    "\n",
    "# Below, write a single expression which, using Pandas, will compute the average\n",
    "# blood pressure reading across all measurements for patients less than 50, using\n",
    "# your combined_patients DataFrame from before.\n",
    "# Be sure to print out the result.\n",
    "# This should print 128.8\n",
    "print()\n",
    "print(combined_patients[combined_patients[\"age\"] < 50][\"blood_pressure\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d66aab3-9354-467a-a427-daeab0bf2de4",
   "metadata": {},
   "source": [
    "## Step 3: Use `merge` To Combine two Pandas `DataFrame` Objects via an Outer Join ##\n",
    "\n",
    "### Background: Outer Joins ###\n",
    "\n",
    "An outer join considers all values between both columns specified in the join, as opposed to only those values which are present in both.\n",
    "In set terms, an inner join (shown previously) only considers values which intersect between the two `DataFrame` objects, whereas an outer join considers all.\n",
    "\n",
    "When calling `merge`, we can optionally set the kind of merge performed by passing a string as a keyword argument `how`.\n",
    "This string defaults to `\"inner\"` (hence a default of an inner join), but we can also use `\"outer\"` for an outer join; the [official Pandas documentation shows all the different options for `how`](https://pandas.pydata.org/docs/reference/api/pandas.merge.html#pandas.merge).\n",
    "This is all illustrated in the next cell, which is an updated version of the hardware inventory from before.\n",
    "In this case, `new_hardware_inventory` adds a new item: `\"jigsaw\"`.\n",
    "Importantly, none of the rows in `hardware_purchases` mention `\"jigsaw\"`.\n",
    "Both an inner join and outer join is performed side-by-side, so we can see the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d272ecca-30c4-4a7c-a7c0-994bb2ce5977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product  price  quantity  location customer_name      when\n",
      "0       hammer   20.0        19     tools         alice  1/2/2025\n",
      "1       hammer   20.0        19     tools           joe  5/6/2025\n",
      "2       wrench   30.0        15     tools         alice  1/2/2025\n",
      "3  screws (20)    2.5       150  hardware           bob  3/4/2025\n",
      "\n",
      "       product  price  quantity  location customer_name      when\n",
      "0       hammer   20.0        19     tools         alice  1/2/2025\n",
      "1       hammer   20.0        19     tools           joe  5/6/2025\n",
      "2       jigsaw   40.0        12     tools           NaN       NaN\n",
      "3  screws (20)    2.5       150  hardware           bob  3/4/2025\n",
      "4       wrench   30.0        15     tools         alice  1/2/2025\n"
     ]
    }
   ],
   "source": [
    "new_hardware_inventory = pd.DataFrame({\"product\": [\"hammer\", \"wrench\", \"screws (20)\", \"jigsaw\"],\n",
    "                                       \"price\": [20, 30, 2.5, 40],\n",
    "                                       \"quantity\": [19, 15, 150, 12],\n",
    "                                       \"location\": [\"tools\", \"tools\", \"hardware\", \"tools\"]})\n",
    "# copied for convenience\n",
    "hardware_purchases = pd.DataFrame({\"customer_name\": [\"alice\", \"alice\", \"bob\", \"joe\"],\n",
    "                                   \"product\": [\"hammer\", \"wrench\", \"screws (20)\", \"hammer\"],\n",
    "                                   \"when\": [\"1/2/2025\", \"1/2/2025\", \"3/4/2025\", \"5/6/2025\"]})\n",
    "inner = new_hardware_inventory.merge(hardware_purchases, on=\"product\", how=\"inner\")\n",
    "print(inner)\n",
    "\n",
    "print()\n",
    "outer = new_hardware_inventory.merge(hardware_purchases, on=\"product\", how=\"outer\")\n",
    "print(outer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cdaedd-738c-4334-83fa-13ee8a32eb9e",
   "metadata": {},
   "source": [
    "As shown, with the inner join, we don't have any rows containing `\"jigsaw\"`.\n",
    "However, we _do_ have a row containing `\"jigsaw\"` for the outer join.\n",
    "With the outer join, because we don't have corresponding information for `\"customer_name\"` or `\"when\"`, those values are filled-in with `NaN`.\n",
    "\n",
    "Graphically, this distinction between an inner join and an outer join for this example is shown below.\n",
    "![venn2](venn2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef029197-96d1-4ffa-bbf0-a2816af7e23b",
   "metadata": {},
   "source": [
    "The inner join will only get the items within the inside (overlapping) part of the diagram.\n",
    "However, the outer join will get everything, including `\"jigsaw\"`.\n",
    "\n",
    "The introduction of `NaN`s may make outer joins seem useless, because this is effectively fake data that is introduced into the data set.\n",
    "Indeed, every non-inner join suffers from the same problem, because fundamentally in these cases, we don't have corresponding data for a given column value.\n",
    "There is a reason why inner join is the default; this usually makes the most sense.\n",
    "While some care needs to be taken with other kinds of joins, this can nonetheless still be useful, depending on what you're doing.\n",
    "For example, let's do a slightly modified version, of this, where:\n",
    "\n",
    "- `new_hardware` is intended only to represent _current_ inventory.\n",
    "- `new_purchases` (a new variable) represents _all_ purchases historically made, including those of items which are no longer kept in stock.\n",
    "\n",
    "This is shown in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab5b3f97-d103-400d-88fd-f28b2caf8109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product  price  quantity  location customer_name       when\n",
      "0       hammer   20.0      19.0     tools         alice   1/2/2025\n",
      "1       hammer   20.0      19.0     tools           joe   5/6/2025\n",
      "2       jigsaw   40.0      12.0     tools           NaN        NaN\n",
      "3  screws (20)    2.5     150.0  hardware           bob   3/4/2025\n",
      "4    table saw    NaN       NaN       NaN          carl  5/12/2015\n",
      "5       wrench   30.0      15.0     tools         alice   1/2/2025\n"
     ]
    }
   ],
   "source": [
    "# copied for convenience\n",
    "new_hardware_inventory = pd.DataFrame({\"product\": [\"hammer\", \"wrench\", \"screws (20)\", \"jigsaw\"],\n",
    "                                       \"price\": [20, 30, 2.5, 40],\n",
    "                                       \"quantity\": [19, 15, 150, 12],\n",
    "                                       \"location\": [\"tools\", \"tools\", \"hardware\", \"tools\"]})\n",
    "new_hardware_purchases = pd.DataFrame({\"customer_name\": [\"alice\", \"alice\", \"bob\", \"joe\", \"carl\"],\n",
    "                                       \"product\": [\"hammer\", \"wrench\", \"screws (20)\", \"hammer\", \"table saw\"],\n",
    "                                       \"when\": [\"1/2/2025\", \"1/2/2025\", \"3/4/2025\", \"5/6/2025\", \"5/12/2015\"]})\n",
    "\n",
    "new_combined_hardware = new_hardware_inventory.merge(new_hardware_purchases, on=\"product\", how=\"outer\")\n",
    "print(new_combined_hardware)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb16f4-d931-4877-998f-69fe232062a1",
   "metadata": {},
   "source": [
    "As shown, table saws are no longer kept in inventory, but one was sold back in 2015.\n",
    "The `new_combined_hardware` table resulted from an outer join, and some `NaN`s are in the table.\n",
    "However, if we were interested in identifying all products ever available for purchase, this data is perfectly fine, as shown in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8cc25df-3dc1-4531-bc93-f767a38d1dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hammer' 'jigsaw' 'screws (20)' 'table saw' 'wrench']\n"
     ]
    }
   ],
   "source": [
    "# The unique() method is on Series objects, and gives back a\n",
    "# NumPy array of all the unique items in a Series\n",
    "print(new_combined_hardware[\"product\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d534e6eb-5182-4bd0-8681-0cffa72e71df",
   "metadata": {},
   "source": [
    "In fact, not only is `new_combined_hardware` ok for this analysis, neither `new_hardware_inventory` nor `new_hardware_purchases` is ok alone for this same analysis.\n",
    "Specifically, `new_hardware_inventory` doesn't contain table saws, since they are no longer sold; only looking at products in `new_hardware_purchases` would miss anything that is no longer sold.\n",
    "On the flip side, `new_hardware_purchases` only details items which have actually been sold; only looking at `new_hardware_purchases` would miss items like jigsaws, which are available for purchase, but no one has bought one yet.\n",
    "\n",
    "### Try this Yourself ###\n",
    "\n",
    "The next cell defines two `DataFrame` objects named `first` and `second`, which share a column named `\"id\"`.\n",
    "Perform an outer join of these two objects, and print out the resulting joined `DataFrame` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8575d17c-4e82-4e2c-8cb4-094aa9d0af36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id  first_value  second_value\n",
      "0   bar          2.0           2.3\n",
      "1   baz          7.0           4.1\n",
      "2  blah          NaN           8.9\n",
      "3   foo          3.0           NaN\n"
     ]
    }
   ],
   "source": [
    "first = pd.DataFrame({\"id\": [\"foo\", \"bar\", \"baz\"],\n",
    "                      \"first_value\": [3, 2, 7]})\n",
    "second = pd.DataFrame({\"id\": [\"bar\", \"baz\", \"blah\"],\n",
    "                       \"second_value\": [2.3, 4.1, 8.9]})\n",
    "\n",
    "# Call the merge method to perform an outer join using column id\n",
    "# Print out the resulting merged DataFrame object\n",
    "df = first.merge(second, on=\"id\", how=\"outer\")\n",
    "print(df)\n",
    "\n",
    "# This should print the following:\n",
    "#      id  first_value  second_value\n",
    "# 0   bar          2.0           2.3\n",
    "# 1   baz          7.0           4.1\n",
    "# 2  blah          NaN           8.9\n",
    "# 3   foo          3.0           NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c468ab-fecc-4cf5-bc8a-c57129aa2e8a",
   "metadata": {},
   "source": [
    "## Step 4: Submit via Canvas ##\n",
    "\n",
    "Be sure to **save your work**, then log into [Canvas](https://canvas.csun.edu/).  Go to the COMP 502 course, and click \"Assignments\" on the left pane.  From there, click \"Assignment 28\".  From there, you can upload your `28_pandas_combining_dataframes.ipynb` file.\n",
    "\n",
    "You can turn in the assignment multiple times, but only the last version you submitted will be graded.\n",
    "\n",
    "### Special Thanks to Dr. Glenn Bruns ###\n",
    "\n",
    "Special thanks to [Dr. Glenn Bruns](https://csumb.edu/scd/glenn-bruns/) at California State University, Monterey Bay, for providing me with closely-related materials which were used in the creation of this assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
